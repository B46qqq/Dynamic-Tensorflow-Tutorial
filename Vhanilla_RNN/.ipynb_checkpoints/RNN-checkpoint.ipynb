{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> VANILLA RNN ON 8*8 MNIST DATASET TO PREDICT TEN CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">Its a dynamic sequence and batch vhanilla rnn. This is created with tensorflow scan and map higher ops!!!! \n",
    "###  <span style=\"color:blue\">This is a base rnn which can be used to create GRU, LSTM, Neural Stack Machine, Neural Turing Machine and  RNN-EM and so on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vhanilla RNN class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_cell(object):\n",
    "\n",
    "    \"\"\"\n",
    "    RNN cell object which takes 3 arguments for initialization.\n",
    "    input_size = Input Vector size\n",
    "    hidden_layer_size = Hidden layer size\n",
    "    target_size = Output vector size\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_size, target_size):\n",
    "\n",
    "        # Initialization of given values\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Weights and Bias for input and hidden tensor\n",
    "        self.Wx = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Wh = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        # Weights for output layers\n",
    "        self.Wo = tf.Variable(tf.truncated_normal(\n",
    "            [self.hidden_layer_size, self.target_size],mean=0,stddev=.01))\n",
    "        self.bo = tf.Variable(tf.truncated_normal([self.target_size],mean=0,stddev=.01))\n",
    "\n",
    "        # Placeholder for input vector with shape[batch, seq, embeddings]\n",
    "        self._inputs = tf.placeholder(tf.float32,\n",
    "                                      shape=[None, None, self.input_size],\n",
    "                                      name='inputs')\n",
    "\n",
    "        # Processing inputs to work with scan function\n",
    "        self.processed_input = process_batch_input_for_RNN(self._inputs)\n",
    "\n",
    "        '''\n",
    "        Initial hidden state's shape is [1,self.hidden_layer_size]\n",
    "        In First time stamp, we are doing dot product with weights to\n",
    "        get the shape of [batch_size, self.hidden_layer_size].\n",
    "        For this dot product tensorflow use broadcasting. But during\n",
    "        Back propagation a low level error occurs.\n",
    "        So to solve the problem it was needed to initialize initial\n",
    "        hiddden state of size [batch_size, self.hidden_layer_size].\n",
    "        So here is a little hack !!!! Getting the same shaped\n",
    "        initial hidden state of zeros.\n",
    "        '''\n",
    "\n",
    "        self.initial_hidden = self._inputs[:, 0, :]\n",
    "        self.initial_hidden = tf.matmul(\n",
    "            self.initial_hidden, tf.zeros([input_size, hidden_layer_size]))\n",
    "\n",
    "    # Function for vhanilla RNN.\n",
    "    def vanilla_rnn(self, previous_hidden_state, x):\n",
    "        \"\"\"\n",
    "        This function takes previous hidden state and input and\n",
    "        outputs current hidden state.\n",
    "        \"\"\"\n",
    "        current_hidden_state = tf.tanh(\n",
    "            tf.matmul(previous_hidden_state, self.Wh) +\n",
    "            tf.matmul(x, self.Wx) + self.bi)\n",
    "\n",
    "        return current_hidden_state\n",
    "\n",
    "    # Function for getting all hidden state.\n",
    "    def get_states(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting all hidden state throuh time\n",
    "        all_hidden_states = tf.scan(self.vanilla_rnn,\n",
    "                                    self.processed_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name='states')\n",
    "\n",
    "        return all_hidden_states\n",
    "\n",
    "    # Function to get output from a hidden layer\n",
    "    def get_output(self, hidden_state):\n",
    "        \"\"\"\n",
    "        This function takes hidden state and returns output\n",
    "        \"\"\"\n",
    "        output = tf.nn.relu(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Function for getting all output layers\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterating through hidden states to get outputs for all timestamp\n",
    "        \"\"\"\n",
    "        all_hidden_states = self.get_states()\n",
    "\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "\n",
    "        return all_outputs\n",
    "\n",
    "\n",
    "# Function to convert batch input data to use scan ops of tensorflow.\n",
    "def process_batch_input_for_RNN(batch_input):\n",
    "    \"\"\"\n",
    "    Process tensor of size [5,3,2] to [3,5,2]\n",
    "    \"\"\"\n",
    "    batch_input_ = tf.transpose(batch_input, perm=[2, 0, 1])\n",
    "    X = tf.transpose(batch_input_)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder and initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 110\n",
    "input_size = 8\n",
    "target_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[None, target_size],name='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing rnn object\n",
    "rnn=RNN_cell( input_size, hidden_layer_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all outputs from rnn\n",
    "outputs = rnn.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting final output through indexing after reversing\n",
    "last_output = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As rnn model output the final layer through Relu activation softmax is used for final output.\n",
    "output=tf.nn.softmax(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing the Cross Entropy loss \n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trainning with Adadelta Optimizer\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculatio of correct prediction and accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Sklearn MNIST dataset.\n",
    "digits = load_digits()\n",
    "X=digits.images\n",
    "Y_=digits.target\n",
    "\n",
    "# One hot encoding\n",
    "Y = sess.run(tf.one_hot(indices=Y_, depth=target_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Train and test Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.22, random_state=42)\n",
    "\n",
    "#Cuttting for simple iteration\n",
    "X_train=X_train[:1400]\n",
    "y_train=y_train[:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMIZ9JJUOINekgpn0EtS4Qx6SSrcPwPmzq2YFmQ2pAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb1bffa2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration: 44 Loss: 0.71091 Train Accuracy: 99.9286 Test Accuracy: 96.4646\n"
     ]
    }
   ],
   "source": [
    "#Iterations to do trainning\n",
    "for epoch in range(120):\n",
    "    \n",
    "    start=0\n",
    "    end=100\n",
    "    for i in range(14):\n",
    "        \n",
    "        X=X_train[start:end]\n",
    "        Y=y_train[start:end]\n",
    "        start=end\n",
    "        end=start+100\n",
    "        sess.run(train_step,feed_dict={rnn._inputs:X, y:Y})\n",
    "\n",
    "    Loss=str(sess.run(cross_entropy,feed_dict={rnn._inputs:X, y:Y}))\n",
    "    Train_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_train, y:y_train}))\n",
    "    Test_accuracy=str(sess.run(accuracy,feed_dict={rnn._inputs:X_test, y:y_test}))\n",
    "    \n",
    "    pl.plot([epoch],Loss,'b.',)\n",
    "    pl.plot([epoch],Train_accuracy,'r*',)\n",
    "    pl.plot([epoch],Test_accuracy,'g+')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())   \n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    print(\"\\rIteration: %s Loss: %s Train Accuracy: %s Test Accuracy: %s\"%(epoch,Loss,Train_accuracy,Test_accuracy)),\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
